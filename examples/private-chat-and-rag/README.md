# 데모: 사내 AI 챗과 RAG

> LO: `LO-사내 AI 챗과 RAG` | 예상 시간: 3분

## 시연 목표

"docker-compose 한 줄로 사내 ChatGPT를 구동하고, 사내 문서를 업로드하면 RAG로 답변한다"

## 사전 요구사항

- Docker Desktop 설치 및 실행 중
- 최소 8GB RAM 여유
- 인터넷 연결 (이미지 다운로드)

## 시연 순서

### 1. 서비스 시작 (사전 준비 — 시연 전 완료)

```bash
cd src

# 호스트에 Ollama가 이미 실행 중인 경우 (권장)
docker compose up -d openwebui

# Ollama도 컨테이너로 실행하려면
# docker compose --profile with-ollama up -d
# docker exec ollama ollama pull qwen3:8b
```

첫 실행 시 이미지 다운로드에 5~10분 소요. **반드시 시연 전 미리 실행**.

### 2. 모델 다운로드 (사전 준비)

```bash
# 호스트 Ollama 사용 시
ollama pull qwen3:8b
```

### 3. 라이브 시연

#### Step 1: 접속 (30초)

- 브라우저에서 `http://localhost:3000` 접속
- 첫 접속 시 관리자 계정 생성
- "ChatGPT와 똑같이 생긴 화면이, 우리 서버에서 돌아가고 있습니다"

#### Step 2: 일반 채팅 (30초)

- 모델 선택: `qwen3:8b` (8GB RAM에서 구동 가능한 고품질 다국어 모델)
- 질문: "인공지능이 뭔지 한 줄로 설명해줘"
- 응답 확인
- "지금 이 응답은 외부 서버가 아니라, 여기 있는 서버에서 나온 겁니다"

#### Step 3: RAG — 사내 문서 업로드 (1분)

- 채팅 입력창 클립 아이콘 → 파일 업로드
- `sample-docs/company-travel-policy.md` 업로드
- 질문: "국내 출장 숙박비가 얼마야?"
- 응답에서 **"팀장 12만원, 일반 10만원"** 등 문서 기반 답변 확인
- "AI가 원래 아는 게 아닙니다. 방금 올린 문서에서 찾아서 답한 겁니다. 이게 RAG입니다"

#### Step 4: 보안 강조 (30초)

- `sample-docs/company-ai-guidelines.md` 업로드
- 질문: "대외비 자료에 클라우드 AI 써도 돼?"
- 응답: "❌ 클라우드 AI 사용 불가, 사내 AI만 허용"
- "이런 보안 규정도 AI가 알고 있으니, 직원들이 실수할 일이 줄어듭니다"
- "지금 보신 건 OpenWebUI라는 '제품 도입' 경로입니다. 기존 시스템과 연동하거나 워크플로우를 커스터마이징하려면 Spring AI로 직접 구현하는 방법도 있습니다"

## 백업 플랜

| 실패 시나리오 | 대응 |
|-------------|------|
| Docker 안 뜸 | `output/` 스크린샷으로 진행 |
| 모델 다운로드 실패 | 사전에 다운로드 완료 확인 필수 |
| RAG 응답 부정확 | "실제 환경에서는 문서를 더 많이 넣을수록 정확해집니다" |

## 핵심 멘트

- "서버 1대 + Docker 한 줄 = 사내 ChatGPT"
- "데이터가 외부로 나가지 않습니다"
- "교육과정에서 이 전체 과정을 실습합니다"
